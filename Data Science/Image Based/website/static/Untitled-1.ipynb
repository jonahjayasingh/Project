{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af763c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3e3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jayas\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clear previous TF session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7db634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Parameters\n",
    "# ============================\n",
    "data_dir = \"data\"\n",
    "img_size = (160, 160)\n",
    "batch_size = 32\n",
    "epochs_top = 10\n",
    "epochs_fine = 5\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "cache_train_path = \"./train_cache.tf-data\"\n",
    "cache_val_path = \"./val_cache.tf-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4feafcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# Clear cache directories if they exist\n",
    "# ============================\n",
    "for cache_path in [cache_train_path, cache_val_path]:\n",
    "    if os.path.exists(cache_path):\n",
    "        shutil.rmtree(cache_path)  # delete cache folder\n",
    "        print(f\"Cleared cache: {cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15872e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114022 files belonging to 15 classes.\n",
      "Using 91218 files for training.\n",
      "Found 114022 files belonging to 15 classes.\n",
      "Using 22804 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Load Dataset\n",
    "# ============================\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92257011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Acne And Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma And Other Malignant Lesions', 'Atopic Dermatitis Photos', 'Ba  Cellulitis', 'Ba Impetigo', 'Benign', 'Bullous Disease Photos', 'Cellulitis Impetigo And Other Bacterial Infections', 'Eczema Photos', 'Exanthems And Drug Eruptions', 'Fu Athlete Foot', 'Fu Nail Fungus', 'Fu Ringworm', 'Hair Loss Photos Alopecia And Other Hair Diseases', 'Heathy']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d34d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Data Augmentation\n",
    "# ============================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.15),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c6e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Preprocessing\n",
    "# ============================\n",
    "def preprocess_train(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = data_augmentation(x, training=True)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_val(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b2ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cache datasets (in-memory, auto-clear on program exit)\n",
    "# ============================\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf106699",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Class Weights\n",
    "# ============================\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train), y=y_train\n",
    ")))\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa052ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Model (MobileNetV2)\n",
    "# ============================\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Compile & Train Top Layers\n",
    "# ============================\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_top = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_top,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# Fine-Tuning Last 50 Layers\n",
    "# ============================\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_fine,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Save Model\n",
    "# ============================\n",
    "save_path = \"./tf_model\"\n",
    "model.save(save_path)\n",
    "print(f\"Model saved to {save_path} ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5689c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow session cleared.\n",
      "üìÅ Dataset path: data\n",
      "üñº Image size: (128, 128), Batch size: 32\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 120610 files for training.\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 30152 files for validation.\n",
      "üìå Classes detected (20): ['Acne And Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma And Other Malignant Lesions', 'Atopic Dermatitis Photos', 'Ba  Cellulitis', 'Ba Impetigo', 'Benign', 'Bullous Disease Photos', 'Cellulitis Impetigo And Other Bacterial Infections', 'Eczema Photos', 'Exanthems And Drug Eruptions', 'Fu Athlete Foot', 'Fu Nail Fungus', 'Fu Ringworm', 'Hair Loss Photos Alopecia And Other Hair Diseases', 'Herpes Hpv And Other Stds Photos', 'Light Diseases And Disorders Of Pigmentation', 'Lupus And Other Connective Tissue Diseases', 'Malignant', 'Melanoma Skin Cancer Nevi And Moles', 'Rashes']\n",
      "üé® Data augmentation pipeline created.\n",
      "‚úÖ Training dataset preprocessed and cached in memory.\n",
      "‚úÖ Validation dataset preprocessed and cached in memory.\n",
      "‚öñÔ∏è Class weights calculated: {0: np.float64(1.1012600438276114), 1: np.float64(1.1069199706314243), 2: np.float64(0.9863428197579326), 3: np.float64(0.9342370255615802), 4: np.float64(0.9215311735941321), 5: np.float64(1.168475101724472), 6: np.float64(0.9756511891279728), 7: np.float64(0.9689106683804627), 8: np.float64(1.122998137802607), 9: np.float64(0.9695337620578778), 10: np.float64(0.9434449311639549), 11: np.float64(0.9240729390131781), 12: np.float64(0.9181638246041413), 13: np.float64(0.9544950933839823), 14: np.float64(0.9710950080515298), 15: np.float64(1.0055861263965316), 16: np.float64(0.9753355976063399), 17: np.float64(1.1099760721516658), 18: np.float64(0.9808880936890045), 19: np.float64(1.0688585607940446)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayas\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\mobilenet_v3.py:452: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß± MobileNetV3 Small model created (feature extraction).\n",
      "‚öôÔ∏è Model compiled.\n",
      "‚èπ EarlyStopping callback created.\n",
      "üöÄ Starting training (feature extraction)...\n",
      "Epoch 1/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3571s\u001b[0m 939ms/step - accuracy: 0.5312 - loss: 1.5058 - val_accuracy: 0.5691 - val_loss: 1.3470\n",
      "Epoch 2/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2982s\u001b[0m 790ms/step - accuracy: 0.5984 - loss: 1.2684 - val_accuracy: 0.5782 - val_loss: 1.3059\n",
      "Epoch 3/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2317s\u001b[0m 613ms/step - accuracy: 0.6123 - loss: 1.2173 - val_accuracy: 0.5797 - val_loss: 1.2993\n",
      "Epoch 4/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2163s\u001b[0m 573ms/step - accuracy: 0.6180 - loss: 1.1934 - val_accuracy: 0.5781 - val_loss: 1.3011\n",
      "Epoch 5/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 508ms/step - accuracy: 0.6213 - loss: 1.1799 - val_accuracy: 0.5767 - val_loss: 1.3054\n",
      "Epoch 6/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2241s\u001b[0m 593ms/step - accuracy: 0.6236 - loss: 1.1713 - val_accuracy: 0.5749 - val_loss: 1.3103\n",
      "‚úÖ Training completed.\n",
      "üíæ Model saved to ./tf_model_1.keras ‚úÖ\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0. Imports & Clear Session\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Clear previous TF session\n",
    "K.clear_session()\n",
    "print(\"‚úÖ TensorFlow session cleared.\")\n",
    "\n",
    "# ============================\n",
    "# 1. Paths & Parameters\n",
    "# ============================\n",
    "data_dir = \"data\"\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs_top = 20\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print(f\"üìÅ Dataset path: {data_dir}\")\n",
    "print(f\"üñº Image size: {img_size}, Batch size: {batch_size}\")\n",
    "\n",
    "# ============================\n",
    "# 2. Load Dataset\n",
    "# ============================\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"üìå Classes detected ({num_classes}): {class_names}\")\n",
    "\n",
    "# ============================\n",
    "# 3. Data Augmentation\n",
    "# ============================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.15),\n",
    "])\n",
    "print(\"üé® Data augmentation pipeline created.\")\n",
    "\n",
    "# ============================\n",
    "# 4. Preprocessing\n",
    "# ============================\n",
    "def preprocess_train(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = data_augmentation(x, training=True)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_val(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "print(\"‚úÖ Training dataset preprocessed and cached in memory.\")\n",
    "\n",
    "val_ds = val_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "print(\"‚úÖ Validation dataset preprocessed and cached in memory.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Class Weights\n",
    "# ============================\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train), y=y_train\n",
    ")))\n",
    "print(f\"‚öñÔ∏è Class weights calculated: {class_weights}\")\n",
    "\n",
    "# ============================\n",
    "# 6. Build Model (MobileNetV3 Small)\n",
    "# ============================\n",
    "base_model = MobileNetV3Small(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "print(\"üß± MobileNetV3 Small model created (feature extraction).\")\n",
    "\n",
    "# ============================\n",
    "# 7. Compile Model\n",
    "# ============================\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"‚öôÔ∏è Model compiled.\")\n",
    "\n",
    "# ============================\n",
    "# 8. Early Stopping Callback\n",
    "# ============================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "print(\"‚èπ EarlyStopping callback created.\")\n",
    "\n",
    "# ============================\n",
    "# 9. Train Model\n",
    "# ============================\n",
    "print(\"üöÄ Starting training (feature extraction)...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_top,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(\"‚úÖ Training completed.\")\n",
    "\n",
    "# ============================\n",
    "# 10. Save Model as HDF5\n",
    "# ============================\n",
    "save_path = \"./tf_model_1.keras\"\n",
    "model.save(save_path)   # No need for save_format='h5'\n",
    "print(f\"üíæ Model saved to {save_path} ‚úÖ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a6ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow session cleared.\n",
      "üìÅ Dataset path: data\n",
      "üñº Image size: (128, 128), Batch size: 32\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 120610 files for training.\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 30152 files for validation.\n",
      "üìå Classes detected (20): ['Acne And Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma And Other Malignant Lesions', 'Atopic Dermatitis Photos', 'Ba  Cellulitis', 'Ba Impetigo', 'Benign', 'Bullous Disease Photos', 'Cellulitis Impetigo And Other Bacterial Infections', 'Eczema Photos', 'Exanthems And Drug Eruptions', 'Fu Athlete Foot', 'Fu Nail Fungus', 'Fu Ringworm', 'Hair Loss Photos Alopecia And Other Hair Diseases', 'Herpes Hpv And Other Stds Photos', 'Light Diseases And Disorders Of Pigmentation', 'Lupus And Other Connective Tissue Diseases', 'Malignant', 'Melanoma Skin Cancer Nevi And Moles', 'Rashes']\n",
      "üé® Data augmentation pipeline created.\n",
      "‚úÖ Training dataset preprocessed and cached in memory.\n",
      "‚úÖ Validation dataset preprocessed and cached in memory.\n",
      "‚öñÔ∏è Class weights calculated: {0: np.float64(1.1012600438276114), 1: np.float64(1.1069199706314243), 2: np.float64(0.9863428197579326), 3: np.float64(0.9342370255615802), 4: np.float64(0.9215311735941321), 5: np.float64(1.168475101724472), 6: np.float64(0.9756511891279728), 7: np.float64(0.9689106683804627), 8: np.float64(1.122998137802607), 9: np.float64(0.9695337620578778), 10: np.float64(0.9434449311639549), 11: np.float64(0.9240729390131781), 12: np.float64(0.9181638246041413), 13: np.float64(0.9544950933839823), 14: np.float64(0.9710950080515298), 15: np.float64(1.0055861263965316), 16: np.float64(0.9753355976063399), 17: np.float64(1.1099760721516658), 18: np.float64(0.9808880936890045), 19: np.float64(1.0688585607940446)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayas\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\mobilenet_v3.py:452: UserWarning: `input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  return MobileNetV3(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß± MobileNetV3 Small model created (feature extraction).\n",
      "‚öôÔ∏è Model compiled.\n",
      "‚èπ EarlyStopping callback created.\n",
      "üöÄ Starting training (feature extraction)...\n",
      "Epoch 1/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3881s\u001b[0m 1s/step - accuracy: 0.5297 - loss: 1.5027 - val_accuracy: 0.5709 - val_loss: 1.3325\n",
      "Epoch 2/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2105s\u001b[0m 556ms/step - accuracy: 0.5970 - loss: 1.2664 - val_accuracy: 0.5796 - val_loss: 1.2973\n",
      "Epoch 3/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2319s\u001b[0m 614ms/step - accuracy: 0.6114 - loss: 1.2159 - val_accuracy: 0.5806 - val_loss: 1.2943\n",
      "Epoch 4/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1863s\u001b[0m 493ms/step - accuracy: 0.6178 - loss: 1.1922 - val_accuracy: 0.5791 - val_loss: 1.2986\n",
      "Epoch 5/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1614s\u001b[0m 427ms/step - accuracy: 0.6216 - loss: 1.1788 - val_accuracy: 0.5779 - val_loss: 1.3047\n",
      "Epoch 6/20\n",
      "\u001b[1m3770/3770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1595s\u001b[0m 422ms/step - accuracy: 0.6236 - loss: 1.1704 - val_accuracy: 0.5759 - val_loss: 1.3111\n",
      "‚úÖ Training completed in 223m 21s\n",
      "üíæ Model saved to ./tf_model.keras ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0. Imports & Clear Session\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time  # for tracking training time\n",
    "\n",
    "# Clear previous TF session\n",
    "K.clear_session()\n",
    "print(\"‚úÖ TensorFlow session cleared.\")\n",
    "\n",
    "# ============================\n",
    "# 1. Paths & Parameters\n",
    "# ============================\n",
    "data_dir = \"data\"\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs_top = 20\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print(f\"üìÅ Dataset path: {data_dir}\")\n",
    "print(f\"üñº Image size: {img_size}, Batch size: {batch_size}\")\n",
    "\n",
    "# ============================\n",
    "# 2. Load Dataset\n",
    "# ============================\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"üìå Classes detected ({num_classes}): {class_names}\")\n",
    "\n",
    "# ============================\n",
    "# 3. Data Augmentation\n",
    "# ============================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.15),\n",
    "])\n",
    "print(\"üé® Data augmentation pipeline created.\")\n",
    "\n",
    "# ============================\n",
    "# 4. Preprocessing\n",
    "# ============================\n",
    "def preprocess_train(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = data_augmentation(x, training=True)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_val(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = preprocess_input(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
    "print(\"‚úÖ Training dataset preprocessed and cached in memory.\")\n",
    "\n",
    "val_ds = val_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
    "print(\"‚úÖ Validation dataset preprocessed and cached in memory.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Class Weights\n",
    "# ============================\n",
    "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train), y=y_train\n",
    ")))\n",
    "print(f\"‚öñÔ∏è Class weights calculated: {class_weights}\")\n",
    "\n",
    "# ============================\n",
    "# 6. Build Model (MobileNetV3 Small)\n",
    "# ============================\n",
    "base_model = MobileNetV3Small(\n",
    "    input_shape=img_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "print(\"üß± MobileNetV3 Small model created (feature extraction).\")\n",
    "\n",
    "# ============================\n",
    "# 7. Compile Model\n",
    "# ============================\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"‚öôÔ∏è Model compiled.\")\n",
    "\n",
    "# ============================\n",
    "# 8. Early Stopping Callback\n",
    "# ============================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "print(\"‚èπ EarlyStopping callback created.\")\n",
    "\n",
    "# ============================\n",
    "# 9. Train Model with Time Tracking\n",
    "# ============================\n",
    "print(\"üöÄ Starting training (feature extraction)...\")\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_top,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "end_time = time.time()  # End timer\n",
    "elapsed_time = end_time - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "print(f\"‚úÖ Training completed in {minutes}m {seconds}s\")\n",
    "\n",
    "# ============================\n",
    "# 10. Save Model in Best Format (.keras)\n",
    "# ============================\n",
    "save_path = \"./tf_model.keras\"\n",
    "model.save(save_path)   # Saves in Keras V3 native format\n",
    "print(f\"üíæ Model saved to {save_path} ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75497210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jayas\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "‚úÖ TensorFlow session cleared.\n",
      "üìÅ Dataset path: data\n",
      "üñº Image size: (224, 224), Batch size: 32\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 120610 files for training.\n",
      "Found 150762 files belonging to 20 classes.\n",
      "Using 30152 files for validation.\n",
      "üìå Classes detected (20): ['Acne And Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma And Other Malignant Lesions', 'Atopic Dermatitis Photos', 'Ba  Cellulitis', 'Ba Impetigo', 'Benign', 'Bullous Disease Photos', 'Cellulitis Impetigo And Other Bacterial Infections', 'Eczema Photos', 'Exanthems And Drug Eruptions', 'Fu Athlete Foot', 'Fu Nail Fungus', 'Fu Ringworm', 'Hair Loss Photos Alopecia And Other Hair Diseases', 'Herpes Hpv And Other Stds Photos', 'Light Diseases And Disorders Of Pigmentation', 'Lupus And Other Connective Tissue Diseases', 'Malignant', 'Melanoma Skin Cancer Nevi And Moles', 'Rashes']\n",
      "üé® Data augmentation pipeline created.\n",
      "‚úÖ Training dataset preprocessed and cached in memory.\n",
      "‚úÖ Validation dataset preprocessed and cached in memory.\n",
      "‚öñÔ∏è Calculating class weights safely...\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0. Imports & Clear Session\n",
    "# ============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess\n",
    "\n",
    "# Clear previous TF session\n",
    "K.clear_session()\n",
    "print(\"‚úÖ TensorFlow session cleared.\")\n",
    "\n",
    "# ============================\n",
    "# 1. Paths & Parameters\n",
    "# ============================\n",
    "data_dir = \"data\"\n",
    "img_size = (224, 224)  # EfficientNetB0 pretrained size\n",
    "batch_size = 32\n",
    "epochs_feature = 10     # feature extraction phase\n",
    "epochs_finetune = 20    # fine-tuning phase\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "checkpoint_path = \"./best_model.keras\"\n",
    "final_model_path = \"./tf_model.keras\"\n",
    "history_path = \"./training_history.json\"\n",
    "\n",
    "print(f\"üìÅ Dataset path: {data_dir}\")\n",
    "print(f\"üñº Image size: {img_size}, Batch size: {batch_size}\")\n",
    "\n",
    "# ============================\n",
    "# 2. Load Dataset\n",
    "# ============================\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"üìå Classes detected ({num_classes}): {class_names}\")\n",
    "\n",
    "# ============================\n",
    "# 3. Data Augmentation\n",
    "# ============================\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.25),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.15),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "\n",
    "print(\"üé® Data augmentation pipeline created.\")\n",
    "\n",
    "# ============================\n",
    "# 4. Preprocessing Pipelines\n",
    "# ============================\n",
    "def preprocess_train(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = data_augmentation(x, training=True)\n",
    "    x = effnet_preprocess(x)\n",
    "    return x, y\n",
    "\n",
    "def preprocess_val(x, y):\n",
    "    x = tf.image.resize(x, img_size)\n",
    "    x = effnet_preprocess(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds = (train_ds\n",
    "            .map(preprocess_train, num_parallel_calls=AUTOTUNE)\n",
    "            .cache()\n",
    "            .prefetch(AUTOTUNE))\n",
    "print(\"‚úÖ Training dataset preprocessed and cached in memory.\")\n",
    "\n",
    "val_ds = (val_ds\n",
    "          .map(preprocess_val, num_parallel_calls=AUTOTUNE)\n",
    "          .cache()\n",
    "          .prefetch(AUTOTUNE))\n",
    "print(\"‚úÖ Validation dataset preprocessed and cached in memory.\")\n",
    "\n",
    "# ============================\n",
    "# 5. Class Weights (memory-safe)\n",
    "# ============================\n",
    "print(\"‚öñÔ∏è Calculating class weights safely...\")\n",
    "label_counts = Counter()\n",
    "for _, y in train_ds.unbatch():\n",
    "    label_counts[int(y.numpy())] += 1\n",
    "\n",
    "total = sum(label_counts.values())\n",
    "class_weights = {cls: total / (len(label_counts) * count) for cls, count in label_counts.items()}\n",
    "print(f\"‚öñÔ∏è Class weights calculated: {class_weights}\")\n",
    "\n",
    "# ============================\n",
    "# 6. Build Model (EfficientNetB0)\n",
    "# ============================\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=img_size + (3,)\n",
    ")\n",
    "base_model.trainable = False  # Phase 1: feature extraction\n",
    "\n",
    "inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "x = inputs\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.35)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"üß± EfficientNetB0 model created.\")\n",
    "\n",
    "# ============================\n",
    "# 7. Compile (Phase 1)\n",
    "# ============================\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name=\"top-3-acc\")\n",
    "    ],\n",
    ")\n",
    "print(\"‚öôÔ∏è Model compiled for feature extraction.\")\n",
    "\n",
    "# ============================\n",
    "# 8. Callbacks\n",
    "# ============================\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_times = []\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._start = time.time()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        dur = time.time() - self._start\n",
    "        self.epoch_times.append(dur)\n",
    "        m, s = int(dur // 60), int(dur % 60)\n",
    "        print(f\"‚è± Epoch {epoch+1} duration: {m}m {s}s\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "time_cb = TimeHistory()\n",
    "\n",
    "# ============================\n",
    "# 9. Train (Phase 1: Feature Extraction)\n",
    "# ============================\n",
    "print(\"üöÄ Starting Phase 1 training (feature extraction)...\")\n",
    "phase1_start = time.time()\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_feature,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint, time_cb],\n",
    ")\n",
    "\n",
    "phase1_elapsed = time.time() - phase1_start\n",
    "m1, s1 = int(phase1_elapsed // 60), int(phase1_elapsed % 60)\n",
    "print(f\"‚úÖ Phase 1 completed in {m1}m {s1}s\")\n",
    "\n",
    "# Load best from phase 1\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "print(\"üîÅ Loaded best Phase 1 checkpoint.\")\n",
    "\n",
    "# ============================\n",
    "# 10. Fine-Tuning Setup (Phase 2)\n",
    "# ============================\n",
    "base_model.trainable = True\n",
    "fine_tune_at = max(0, len(base_model.layers) - 50)\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = (i >= fine_tune_at)\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name=\"top-3-acc\")\n",
    "    ],\n",
    ")\n",
    "print(f\"üõ† Fine-tuning from layer index {fine_tune_at}. Recompiled with LR=1e-5.\")\n",
    "\n",
    "# ============================\n",
    "# 11. Train (Phase 2: Fine-Tuning)\n",
    "# ============================\n",
    "print(\"üöÄ Starting Phase 2 training (fine-tuning)...\")\n",
    "phase2_start = time.time()\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_finetune,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint, time_cb],\n",
    ")\n",
    "\n",
    "phase2_elapsed = time.time() - phase2_start\n",
    "m2, s2 = int(phase2_elapsed // 60), int(phase2_elapsed % 60)\n",
    "print(f\"‚úÖ Phase 2 completed in {m2}m {s2}s\")\n",
    "\n",
    "# Load best overall\n",
    "model = tf.keras.models.load_model(checkpoint_path)\n",
    "print(\"üèÜ Loaded best checkpoint across both phases.\")\n",
    "\n",
    "# ============================\n",
    "# 12. Save Final Model & History\n",
    "# ============================\n",
    "model.save(final_model_path)\n",
    "print(f\"üíæ Final model saved to {final_model_path} ‚úÖ\")\n",
    "\n",
    "full_history = {}\n",
    "for key in set(list(history1.history.keys()) + list(history2.history.keys())):\n",
    "    full_history[key] = history1.history.get(key, []) + history2.history.get(key, [])\n",
    "\n",
    "with open(history_path, \"w\") as f:\n",
    "    json.dump(full_history, f)\n",
    "print(f\"üìä Training history saved to {history_path} ‚úÖ\")\n",
    "\n",
    "# ============================\n",
    "# 13. Summary\n",
    "# ============================\n",
    "total_elapsed = phase1_elapsed + phase2_elapsed\n",
    "mt, st = int(total_elapsed // 60), int(total_elapsed % 60)\n",
    "print(f\"‚è± Total training time (both phases): {mt}m {st}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40d10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
