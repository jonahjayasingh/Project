{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract Resume Texts ---\n",
    "RESUME_FOLDER = \"data/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c895181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_texts = []\n",
    "resume_files = []\n",
    "\n",
    "all_files = [os.path.join(root, file)\n",
    "             for root, dirs, files in os.walk(RESUME_FOLDER)\n",
    "             for file in files if file.lower().endswith(\".pdf\")]\n",
    "\n",
    "for file_path in tqdm(all_files, desc=\"Extracting PDFs\"):\n",
    "    text = extract_text_from_pdf(file_path)\n",
    "    if text.strip():\n",
    "        resume_texts.append(text)\n",
    "        resume_files.append(file_path)\n",
    "\n",
    "df_resumes = pd.DataFrame({\"file\": resume_files, \"text\": resume_texts})\n",
    "print(f\"Loaded {len(df_resumes)} resumes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sample Job Description ---\n",
    "job_description = \"\"\"\n",
    "Looking for a Data Scientist with Python, Machine Learning,\n",
    "Deep Learning, and NLP experience.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f440fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TF-IDF Vectorization ---\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "all_texts = [job_description] + df_resumes['text'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(all_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute similarity scores ---\n",
    "similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "df_resumes['score'] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e901786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: Train a model to predict scores ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix[1:], similarity_scores, test_size=0.2, random_state=42)\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3201322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rank resumes ---\n",
    "ranked_resumes = df_resumes.sort_values(by='score', ascending=False)\n",
    "print(\"\\nTop 5 resumes:\")\n",
    "for idx, row in ranked_resumes.head(5).iterrows():\n",
    "    print(f\"{row['file']} ‚Äî Score: {row['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_teacher_score(resume_text):\n",
    "    # --- Skills match ---\n",
    "    skill_keywords = [\"teaching\", \"classroom management\", \"lesson planning\", \"curriculum\", \"education\", \"pedagogy\"]\n",
    "    skills_score = sum(1 for skill in skill_keywords if skill.lower() in resume_text.lower()) / len(skill_keywords)\n",
    "    \n",
    "    # --- Experience match ---\n",
    "    import re\n",
    "    years = re.findall(r'(\\d+)\\s+years?', resume_text.lower())\n",
    "    exp_score = min(sum(int(y) for y in years) / 20, 1)  # normalize to 0-1, max 20 years\n",
    "    \n",
    "    # --- Education match ---\n",
    "    edu_keywords = [\"bachelor\", \"master\", \"phd\", \"education degree\", \"teaching certification\"]\n",
    "    edu_score = sum(1 for edu in edu_keywords if edu in resume_text.lower()) / len(edu_keywords)\n",
    "    \n",
    "    # --- Weighted final score ---\n",
    "    final_score = 0.4*skills_score + 0.4*exp_score + 0.2*edu_score\n",
    "    return final_score\n",
    "\n",
    "# Apply to your resumes\n",
    "df_resumes['teacher_score'] = df_resumes['text'].apply(calculate_teacher_score)\n",
    "df_resumes = df_resumes.sort_values(by='teacher_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Teacher resumes:\")\n",
    "for idx, row in df_resumes.head(5).iterrows():\n",
    "    print(f\"{row['file']} ‚Äî Teacher Score: {row['teacher_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import PyPDF2\n",
    "\n",
    "# --- Extract text from a single PDF ---\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- Load pre-trained transformer ---\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- Job description + Resume ---\n",
    "resume_file = \"data/data/TEACHER/90363254.pdf\"\n",
    "resume_text = extract_text_from_pdf(resume_file)\n",
    "\n",
    "job_description = \"\"\"\n",
    "Looking for a Teacher with strong classroom management, lesson planning,\n",
    "and education background. Teaching certification is a plus.\n",
    "\"\"\"\n",
    "\n",
    "# --- Create embeddings ---\n",
    "embeddings = model.encode([job_description, resume_text], convert_to_tensor=True)\n",
    "\n",
    "# --- Cosine similarity ---\n",
    "similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
    "\n",
    "print(f\"Resume: {resume_file}\")\n",
    "print(f\"Deep NLP Similarity Score: {similarity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66687a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Load model (PyTorch only) ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # small, fast, good for semantic similarity\n",
    "\n",
    "# --- Function: Extract text from a PDF ---\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "# --- Job description (your target text) ---\n",
    "job_description = \"\"\"\n",
    "We are seeking a passionate and creative Arts Teacher to inspire students through visual and performing arts. \n",
    "The ideal candidate will have strong skills in painting, drawing, sculpture, or digital media, along with experience \n",
    "in art history and contemporary practices. Responsibilities include developing engaging lesson plans, encouraging \n",
    "creative expression, and helping students build technical and conceptual skills. Strong classroom management, \n",
    "curriculum planning, and the ability to foster an inclusive and motivating environment are essential.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# --- Encode job description once ---\n",
    "job_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "\n",
    "# --- Folder containing resumes ---\n",
    "resume_folder = \"data/data/ARTS\"   # change to your folder path\n",
    "\n",
    "# --- Loop through all PDFs in the folder ---\n",
    "results = []\n",
    "for file_name in os.listdir(resume_folder):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(resume_folder, file_name)\n",
    "        resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        # Encode resume text\n",
    "        resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        score = util.pytorch_cos_sim(job_embedding, resume_embedding).item()\n",
    "\n",
    "        results.append((file_name, score))\n",
    "\n",
    "# --- Sort results by score (highest first) ---\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --- Print top matches ---\n",
    "print(\"Top matching resumes:\")\n",
    "for file_name, score in results[:5]:\n",
    "    print(f\"{file_name} ‚Äî Score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b72166",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow tensorflow-macos tensorflow-metal -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "John Doe\n",
    "123 Main Street, New York, NY 10001\n",
    "john.doe@example.com | (123) 456-7890\n",
    "\n",
    "Career Objective:\n",
    "Motivated data scientist with a strong background in computer science and statistics, seeking to contribute to innovative data projects in a dynamic organization.\n",
    "\n",
    "Education:\n",
    "Bachelor of Science in Computer Science, NYU, 2018 ‚Äì 2022\n",
    "High School Diploma, Lincoln High School, 2014 ‚Äì 2018\n",
    "\n",
    "Skills:\n",
    "Python, Java, SQL, Data Analysis, Machine Learning, Deep Learning, TensorFlow, PyTorch, Excel, HTML, CSS, JavaScript\n",
    "\n",
    "Professional Experience:\n",
    "Data Science Intern ‚Äì DataWorks Inc. (June 2021 ‚Äì August 2021)\n",
    "- Built predictive models using Python and scikit-learn\n",
    "- Cleaned and analyzed large datasets with pandas and NumPy\n",
    "- Collaborated with cross-functional teams to deliver insights\n",
    "\n",
    "Junior Data Analyst ‚Äì Insight Analytics (July 2022 ‚Äì Present)\n",
    "- Developed dashboards in Power BI and Tableau\n",
    "- Automated ETL pipelines using Python scripts\n",
    "- Conducted A/B tests to optimize marketing strategies\n",
    "\n",
    "Certifications:\n",
    "Google Data Analytics Certificate\n",
    "AWS Certified Data Practitioner\n",
    "\n",
    "Projects:\n",
    "- Customer Churn Prediction using Logistic Regression\n",
    "- Movie Recommendation System with Collaborative Filtering\n",
    "\n",
    "Languages:\n",
    "English (Fluent), Spanish (Conversational)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bccc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import pdfplumber  # <-- new import\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load PDF and extract text\n",
    "def load_resume_text(file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Keywords\n",
    "EDU_KEYWORDS = [\n",
    "    'bachelor', 'master', 'phd', 'high school', 'secondary school',\n",
    "    'bs', 'ms', 'b.sc', 'm.sc', 'mba', 'b.e', 'm.e', 'm.tech', 'b.tech'\n",
    "]\n",
    "\n",
    "SKILL_KEYWORDS = [\n",
    "    'python', 'java', 'c++', 'machine learning', 'deep learning',\n",
    "    'sql', 'excel', 'data analysis', 'tensorflow', 'pytorch',\n",
    "    'html', 'css', 'javascript', 'react', 'node.js'\n",
    "]\n",
    "\n",
    "EXPERIENCE_KEYWORDS = [\n",
    "    'experience', 'employment history', 'work history', 'professional experience'\n",
    "]\n",
    "\n",
    "def extract_education(text):\n",
    "    education = []\n",
    "    for line in text.split('\\n'):\n",
    "        if any(keyword in line.lower() for keyword in EDU_KEYWORDS):\n",
    "            education.append(line.strip())\n",
    "    return education\n",
    "\n",
    "def extract_skills(text):\n",
    "    text = text.lower()\n",
    "    found_skills = [skill for skill in SKILL_KEYWORDS if skill.lower() in text]\n",
    "    return list(set(found_skills))\n",
    "\n",
    "def extract_experience(text):\n",
    "    experience_section = \"\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in EXPERIENCE_KEYWORDS):\n",
    "            # Grab next 10 lines as naive experience section\n",
    "            experience_section = \"\\n\".join(lines[i:i+10])\n",
    "            break\n",
    "    return experience_section.strip()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    resume_text = load_resume_text('/Volumes/CrucialX9/Project/Data Science/NLP/data/data/INFORMATION-TECHNOLOGY/10265057.pdf')\n",
    "\n",
    "    education = extract_education(resume_text)\n",
    "    skills = extract_skills(resume_text)\n",
    "    experience = extract_experience(resume_text)\n",
    "\n",
    "    print(\"üìö Education:\")\n",
    "    for item in education:\n",
    "        print(\" -\", item)\n",
    "\n",
    "    print(\"\\nüõ†Ô∏è Skills:\")\n",
    "    for skill in skills:\n",
    "        print(\" -\", skill)\n",
    "\n",
    "    print(\"\\nüíº Experience Snippet:\")\n",
    "    print(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import pdfplumber\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load spaCy NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load PDF and extract text\n",
    "def load_resume_text(file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract person's name using NLP from the top lines of resume\n",
    "def extract_name(text):\n",
    "    top_lines = '\\n'.join(text.strip().split('\\n')[:10])  # first 10 lines\n",
    "    doc = nlp(top_lines)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            return ent.text.strip()\n",
    "    return \"Candidate\"  # fallback name if no person entity found\n",
    "\n",
    "# Keywords\n",
    "EDU_KEYWORDS = [\n",
    "    'bachelor', 'master', 'phd', 'high school', 'secondary school',\n",
    "    'bs', 'ms', 'b.sc', 'm.sc', 'mba', 'b.e', 'm.e', 'm.tech', 'b.tech'\n",
    "]\n",
    "\n",
    "SKILL_KEYWORDS = [\n",
    "    # üîß Technical & IT Skills\n",
    "    'python', 'java', 'c++', 'c#', 'ruby', 'go', 'r', 'javascript',\n",
    "    'sql', 'nosql', 'html', 'css', 'react', 'angular', 'vue.js', 'node.js',\n",
    "    'flask', 'django', 'spring boot', 'dotnet', '.net', 'php',\n",
    "    'machine learning', 'deep learning', 'artificial intelligence', 'data science',\n",
    "    'data analysis', 'data engineering', 'big data', 'data visualization',\n",
    "    'pandas', 'numpy', 'matplotlib', 'tensorflow', 'pytorch',\n",
    "    'cloud computing', 'aws', 'azure', 'google cloud platform', 'gcp',\n",
    "    'docker', 'kubernetes', 'jenkins', 'devops', 'ci/cd',\n",
    "    'linux', 'windows server', 'bash', 'powershell',\n",
    "    'networking', 'cybersecurity', 'penetration testing', 'firewall', 'vpn',\n",
    "    'sap', 'abap', 'hana', 'ecc', 'erp', 'oracle', 'crm',\n",
    "    'sql server', 'postgresql', 'mongodb', 'redis', 'elasticsearch',\n",
    "    'jira', 'confluence', 'git', 'github', 'gitlab',\n",
    "    'itil', 'agile', 'scrum', 'kanban',\n",
    "    \n",
    "    # üìä Business, Finance, and Management\n",
    "    'accounting', 'bookkeeping', 'finance', 'financial analysis',\n",
    "    'budgeting', 'forecasting', 'auditing', 'payroll',\n",
    "    'tax preparation', 'quickbooks', 'xero', 'tally', 'erp systems',\n",
    "    'microsoft excel', 'microsoft word', 'microsoft powerpoint',\n",
    "    'data entry', 'ms office', 'spreadsheet analysis',\n",
    "    'operations management', 'supply chain', 'logistics', 'inventory management',\n",
    "    'project management', 'program management', 'pmp', 'six sigma', 'lean',\n",
    "    'procurement', 'vendor management', 'contract negotiation',\n",
    "\n",
    "    # üõçÔ∏è Marketing, Sales, and Customer Support\n",
    "    'salesforce', 'hubspot', 'seo', 'sem', 'google analytics',\n",
    "    'email marketing', 'content marketing', 'copywriting', 'adwords',\n",
    "    'market research', 'branding', 'social media marketing',\n",
    "    'customer service', 'crm', 'retail sales', 'upselling',\n",
    "    'cold calling', 'account management', 'b2b sales', 'lead generation',\n",
    "    \n",
    "    # üßë‚Äçüè´ Education and Training\n",
    "    'lesson planning', 'curriculum development', 'teaching',\n",
    "    'classroom management', 'online teaching', 'tutoring', 'e-learning',\n",
    "    'blackboard', 'moodle', 'canvas', 'zoom', 'google classroom',\n",
    "    'student assessment', 'education administration',\n",
    "\n",
    "    # üß™ Healthcare, Science, and Research\n",
    "    'nursing', 'patient care', 'clinical research', 'healthcare management',\n",
    "    'medical billing', 'medical coding', 'emr', 'ehr',\n",
    "    'laboratory testing', 'phlebotomy', 'health informatics',\n",
    "    'data collection', 'data interpretation', 'quantitative research',\n",
    "\n",
    "    # üõ†Ô∏è Trades, Construction, and Engineering\n",
    "    'autocad', 'solidworks', 'mechanical engineering',\n",
    "    'civil engineering', 'electrical engineering', 'hvac',\n",
    "    'blueprint reading', 'welding', 'plumbing', 'carpentry',\n",
    "    'osha', 'project scheduling', 'site supervision',\n",
    "\n",
    "    # üß† Soft Skills (ATS-friendly)\n",
    "    'communication', 'teamwork', 'leadership', 'problem solving',\n",
    "    'time management', 'critical thinking', 'adaptability',\n",
    "    'creativity', 'collaboration', 'decision making',\n",
    "    'attention to detail', 'multitasking', 'empathy', 'resilience'\n",
    "]\n",
    "\n",
    "\n",
    "EXPERIENCE_KEYWORDS = [\n",
    "    'experience', 'employment history', 'work history', 'professional experience'\n",
    "]\n",
    "\n",
    "# Fuzzy matching helper\n",
    "def fuzzy_match(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() >= threshold\n",
    "\n",
    "# Extract section from resume\n",
    "def extract_section(text, keywords, window=10):\n",
    "    lines = text.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        line_lower = line.lower()\n",
    "        if any(k in line_lower for k in keywords):\n",
    "            return '\\n'.join(lines[i:i+window])\n",
    "    return \"\"\n",
    "\n",
    "# Extract education\n",
    "def extract_education(text):\n",
    "    edu_section = extract_section(text, EDU_KEYWORDS)\n",
    "    education = []\n",
    "    for line in edu_section.split('\\n'):\n",
    "        if any(fuzzy_match(keyword, line) for keyword in EDU_KEYWORDS):\n",
    "            education.append(line.strip())\n",
    "    return education\n",
    "\n",
    "# Extract skills\n",
    "def extract_skills(text):\n",
    "    skills_found = set()\n",
    "    text_lower = text.lower()\n",
    "    for skill in SKILL_KEYWORDS:\n",
    "        if skill in text_lower:\n",
    "            skills_found.add(skill)\n",
    "    return list(skills_found)\n",
    "\n",
    "# Extract experience section\n",
    "def extract_experience(text):\n",
    "    exp_section = extract_section(text, EXPERIENCE_KEYWORDS)\n",
    "    return exp_section.strip()\n",
    "\n",
    "# Extract skills/edu from job description\n",
    "def extract_job_requirements(job_desc):\n",
    "    job_desc_lower = job_desc.lower()\n",
    "    job_skills = [skill for skill in SKILL_KEYWORDS if skill in job_desc_lower]\n",
    "    job_edu = [edu for edu in EDU_KEYWORDS if edu in job_desc_lower]\n",
    "    return job_skills, job_edu\n",
    "\n",
    "# Compute ATS score\n",
    "def ats_score(resume_edu, resume_skills, resume_exp_text, job_edu, job_skills):\n",
    "    edu_match = 1 if any(any(job_e in edu.lower() for job_e in job_edu) for edu in resume_edu) else 0\n",
    "\n",
    "    skill_match = len(set(resume_skills).intersection(set(job_skills))) / len(job_skills) if job_skills else 0\n",
    "\n",
    "    exp_text = resume_exp_text.lower()\n",
    "    exp_matches = sum(1 for skill in job_skills if skill in exp_text)\n",
    "    exp_match = exp_matches / len(job_skills) if job_skills else 0\n",
    "\n",
    "    score = (edu_match * 0.3 + skill_match * 0.5 + exp_match * 0.2) * 100\n",
    "    return round(score, 2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your resume PDF\n",
    "    resume_path = 'surya resume new (1) (1).pdf'  # change as needed\n",
    "    resume_text = load_resume_text(resume_path)\n",
    "\n",
    "    # Extract candidate name automatically\n",
    "    user_name = extract_name(resume_text)\n",
    "\n",
    "    # Dummy Job Description\n",
    "    JOB_DESCRIPTION = \"\"\"\n",
    "   We are looking for energetic and driven Sales & Marketing Interns to join our team at Alzone Software. This internship offers hands-on experience in various aspects of sales and marketing, including cold calling, lead generation, social media marketing, campaign execution, and CRM management.\n",
    "\n",
    "Successful interns may be offered a full-time salaried role based on performance after the internship.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract features from resume\n",
    "    education = extract_education(resume_text)\n",
    "    skills = extract_skills(resume_text)\n",
    "    experience = extract_experience(resume_text)\n",
    "\n",
    "    # Extract job requirements\n",
    "    job_skills, job_edu = extract_job_requirements(JOB_DESCRIPTION)\n",
    "\n",
    "    # Calculate ATS score\n",
    "    score = ats_score(education, skills, experience, job_edu, job_skills)\n",
    "\n",
    "    # Print Output\n",
    "    print(f\"\\nüëã Hello {user_name}, here's your resume match analysis:\\n\")\n",
    "\n",
    "    print(\"üìö Education Found in Resume:\")\n",
    "    if education:\n",
    "        for item in education:\n",
    "            print(\" -\", item)\n",
    "    else:\n",
    "        print(\" - No matching education found.\")\n",
    "\n",
    "    print(\"\\nüõ†Ô∏è Skills Found in Resume:\")\n",
    "    if skills:\n",
    "        for skill in skills:\n",
    "            print(\" -\", skill)\n",
    "    else:\n",
    "        print(\" - No matching skills found.\")\n",
    "\n",
    "    print(\"\\nüíº Experience Section Snippet:\")\n",
    "    print(experience if experience else \" - No experience section found.\")\n",
    "\n",
    "    print(f\"\\n‚úÖ ATS Matching Score: {score} / 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c288af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import pdfplumber\n",
    "from nltk.corpus import stopwords\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Skill and education keywords\n",
    "SKILL_KEYWORDS = [\n",
    "    # IT & Tech\n",
    "    'python', 'java', 'c++', 'c#', 'ruby', 'go', 'r', 'sql', 'html', 'css',\n",
    "    'javascript', 'react', 'node.js', 'flask', 'django', 'tensorflow', 'pytorch',\n",
    "    'machine learning', 'deep learning', 'data science', 'data analysis',\n",
    "    'big data', 'devops', 'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'git',\n",
    "    'sap', 'abap', 'hana', 'ecc', 'erp', 'linux', 'agile', 'scrum',\n",
    "\n",
    "    # Business & Management\n",
    "    'accounting', 'bookkeeping', 'finance', 'payroll', 'forecasting', 'budgeting',\n",
    "    'project management', 'pmp', 'six sigma', 'lean', 'inventory', 'logistics',\n",
    "    'vendor management', 'contract negotiation',\n",
    "\n",
    "    # Marketing & Sales\n",
    "    'marketing', 'sales', 'seo', 'sem', 'social media marketing',\n",
    "    'crm', 'email marketing', 'branding', 'lead generation',\n",
    "\n",
    "    # Education & Training\n",
    "    'teaching', 'tutoring', 'curriculum development', 'classroom management',\n",
    "\n",
    "    # Admin & Support\n",
    "    'data entry', 'ms office', 'excel', 'powerpoint', 'word',\n",
    "    'customer service', 'front desk', 'scheduling', 'document handling',\n",
    "\n",
    "    # Soft Skills\n",
    "    'communication', 'teamwork', 'leadership', 'problem solving',\n",
    "    'adaptability', 'multitasking', 'collaboration'\n",
    "]\n",
    "EDU_KEYWORDS = [\n",
    "    'bachelor', 'master', 'phd', 'mba', 'high school', 'secondary school',\n",
    "    'b.sc', 'm.sc', 'bba', 'bca', 'mca', 'b.com', 'm.com'\n",
    "]\n",
    "\n",
    "EXPERIENCE_KEYWORDS = ['experience', 'employment history', 'work history', 'professional experience']\n",
    "\n",
    "# Helper functions\n",
    "def fuzzy_match(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() >= threshold\n",
    "\n",
    "def load_resume_text(file_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_section(text, keywords, window=10):\n",
    "    lines = text.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(k in line.lower() for k in keywords):\n",
    "            return '\\n'.join(lines[i:i+window])\n",
    "    return \"\"\n",
    "\n",
    "def extract_education(text):\n",
    "    section = extract_section(text, EDU_KEYWORDS)\n",
    "    return [line.strip() for line in section.split('\\n') if any(k in line.lower() for k in EDU_KEYWORDS)]\n",
    "\n",
    "def extract_skills(text):\n",
    "    found = set()\n",
    "    text_lower = text.lower()\n",
    "    for skill in SKILL_KEYWORDS:\n",
    "        if skill in text_lower:\n",
    "            found.add(skill)\n",
    "    return list(found)\n",
    "\n",
    "def extract_experience(text):\n",
    "    return extract_section(text, EXPERIENCE_KEYWORDS).strip()\n",
    "\n",
    "def extract_name(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text\n",
    "    return \"Candidate\"\n",
    "\n",
    "def extract_job_requirements(desc):\n",
    "    desc_lower = desc.lower()\n",
    "    skills = [k for k in SKILL_KEYWORDS if k in desc_lower]\n",
    "    edu = [e for e in EDU_KEYWORDS if e in desc_lower]\n",
    "    return skills, edu\n",
    "\n",
    "def ats_score(resume_edu, resume_skills, resume_exp_text, job_edu, job_skills):\n",
    "    edu_match = 1 if any(job_e in edu.lower() for edu in resume_edu for job_e in job_edu) else 0\n",
    "    skill_match = len(set(resume_skills) & set(job_skills)) / len(job_skills) if job_skills else 0\n",
    "    exp_match = sum(1 for skill in job_skills if skill in resume_exp_text.lower()) / len(job_skills) if job_skills else 0\n",
    "    score = (edu_match * 0.3 + skill_match * 0.5 + exp_match * 0.2) * 100\n",
    "    return round(score, 2)\n",
    "\n",
    "# Job Description\n",
    "JOB_DESCRIPTION = \"\"\"\n",
    "We are hiring a Marketing and Front Desk Coordinator with strong communication, lead generation, and social media skills.\n",
    "Experience with CRM tools, Excel, and basic data entry is required.\n",
    "A bachelor's degree in business or marketing is preferred.\n",
    "\"\"\"\n",
    "\n",
    "# --- Batch Resume Processing ---\n",
    "def process_resumes(resume_folder_path):\n",
    "    job_skills, job_edu = extract_job_requirements(JOB_DESCRIPTION)\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(resume_folder_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(resume_folder_path, filename)\n",
    "            try:\n",
    "                resume_text = load_resume_text(file_path)\n",
    "                name = extract_name(resume_text)\n",
    "                education = extract_education(resume_text)\n",
    "                skills = extract_skills(resume_text)\n",
    "                experience = extract_experience(resume_text)\n",
    "                score = ats_score(education, skills, experience, job_edu, job_skills)\n",
    "\n",
    "                result = {\n",
    "                    'Name': name,\n",
    "                    'File': filename,\n",
    "                    'Education': education,\n",
    "                    'Skills': skills,\n",
    "                    'Score': score\n",
    "                }\n",
    "\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error reading {filename}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Run the System ---\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"/Volumes/CrucialX9/Project/Data Science/NLP/data/data/BUSINESS-DEVELOPMENT\"  # üëà Replace with your folder path\n",
    "    match_results = process_resumes(folder)\n",
    "    match_results.sort(key=lambda x: x['Score'], reverse=True)\n",
    "    for res in match_results:\n",
    "        print(f\"\\nüë§ {res['Name']} ({res['File']})\")\n",
    "        print(\"üìö Education:\", res['Education'] or \"None found\")\n",
    "        print(\"üõ†Ô∏è Skills:\", ', '.join(res['Skills']) or \"None found\")\n",
    "        print(f\"‚úÖ ATS Score: {res['Score']} / 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc512d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
